{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPWonUiHfbeht7titUkQT0N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ranabilal09/SQL-Research-Assistant/blob/main/SQL_Research_Assistent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LA4SFMVnXSa",
        "outputId": "29c4da6d-1950-4bf8-8f3d-fa2587ed3289",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.11)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.10/dist-packages (0.2.59)\n",
            "Requirement already satisfied: langchain-ollama in /usr/local/lib/python3.10/dist-packages (0.2.1)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.10/dist-packages (0.3.11)\n",
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.10/dist-packages (2.0.7)\n",
            "Requirement already satisfied: langserve in /usr/local/lib/python3.10/dist-packages (0.3.0)\n",
            "Requirement already satisfied: arxiv in /usr/local/lib/python3.10/dist-packages (2.1.3)\n",
            "Requirement already satisfied: duckduckgo-search in /usr/local/lib/python3.10/dist-packages (6.4.1)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.9)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.24 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.24)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.2)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.147)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.10.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.4 in /usr/local/lib/python3.10/dist-packages (from langgraph) (2.0.8)\n",
            "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in /usr/local/lib/python3.10/dist-packages (from langgraph) (0.1.43)\n",
            "Requirement already satisfied: ollama<1,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain-ollama) (0.4.4)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.4.0)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.6.1)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (1.2.0)\n",
            "Requirement already satisfied: google-generativeai<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (0.8.3)\n",
            "Requirement already satisfied: httpx<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langserve) (0.27.2)\n",
            "Requirement already satisfied: orjson<4,>=2 in /usr/local/lib/python3.10/dist-packages (from langserve) (3.10.12)\n",
            "Requirement already satisfied: feedparser~=6.0.10 in /usr/local/lib/python3.10/dist-packages (from arxiv) (6.0.11)\n",
            "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.10/dist-packages (from duckduckgo-search) (8.1.7)\n",
            "Requirement already satisfied: primp>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from duckduckgo-search) (0.8.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.23.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.10/dist-packages (from feedparser~=6.0.10->arxiv) (1.0.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.10 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.6.10)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.151.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.25.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.10->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.25.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1.0,>=0.23.0->langserve) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1.0,>=0.23.0->langserve) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1.0,>=0.23.0->langserve) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1.0,>=0.23.0->langserve) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1.0,>=0.23.0->langserve) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1.0,>=0.23.0->langserve) (0.14.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.24->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.24->langchain) (24.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.4->langgraph) (1.1.0)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.66.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.9)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.24->langchain) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1.0,>=0.23.0->langserve) (1.2.2)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.68.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.62.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (3.2.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain langgraph langchain-ollama langchain_community langchain-google-genai langserve arxiv duckduckgo-search"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata , drive\n",
        "import os\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "api = userdata.get('Gemini_Api_Key')\n",
        "os.environ['GOOGLE_API_KEY'] = api\n",
        "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get('langchai_api_key')\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = 'SQL-Research-Assistent'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-C6NdI_n4Lf",
        "outputId": "960b2801-f78d-4cf1-8c2f-9e41ae93cb99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_ollama.llms import OllamaLLM\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.pydantic_v1 import BaseModel\n",
        "from langchain.schema.runnable import RunnablePassthrough,RunnableLambda\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "from langchain.utilities import SQLDatabase\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "import sqlite3\n",
        "\n",
        "import requests\n",
        "from langchain_community.utilities.sql_database import SQLDatabase\n",
        "from sqlalchemy import create_engine\n",
        "from sqlalchemy.pool import StaticPool\n",
        "\n",
        "\n",
        "def get_engine_for_chinook_db():\n",
        "    \"\"\"Pull sql file, populate in-memory database, and create engine.\"\"\"\n",
        "    url = \"https://raw.githubusercontent.com/lerocha/chinook-database/master/ChinookDatabase/DataSources/Chinook_Sqlite.sql\"\n",
        "    response = requests.get(url)\n",
        "    sql_script = response.text\n",
        "\n",
        "    connection = sqlite3.connect(\":memory:\", check_same_thread=False)\n",
        "    connection.executescript(sql_script)\n",
        "    return create_engine(\n",
        "        \"sqlite://\",\n",
        "        creator=lambda: connection,\n",
        "        poolclass=StaticPool,\n",
        "        connect_args={\"check_same_thread\": False},\n",
        "    )\n",
        "\n",
        "\n",
        "engine = get_engine_for_chinook_db()\n",
        "\n",
        "db = SQLDatabase(engine)\n",
        "\n",
        "def get_schema(_):\n",
        "  return db.get_table_info()\n",
        "\n",
        "def get_data(query:str):\n",
        "  return db.run(query)\n",
        "\n",
        "#prompt\n",
        "\n",
        "template = \"\"\"Based on the table schema below , write a SQL query that would anser the user's question:\n",
        "{schema}\n",
        "\n",
        "Question:{question}\n",
        "\n",
        "SQL Query must be in string format and remember that don't use the name 'sql'\n",
        "and backticks (like ```) in response essentially . Use only SELECT and FROM in query, essentially Don't use WHERE word.\n",
        "you must respond string of query in the following format:\n",
        "SELECT column1, column2,...  FROM table_name\n",
        "SQL Query:\"\"\" #node: E501\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"Given a input Question , convert it into a SQL query and remember that don't use the name 'sql' and backtikes (```) in the response. No pre-amble.\"),\n",
        "        (\"human\",template),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model = ChatGoogleGenerativeAI(model= \"gemini-1.5-flash-8b\")\n",
        "\n",
        "#Chain query\n",
        "\n",
        "sql_chain = (\n",
        "    RunnablePassthrough.assign(\n",
        "        schema=get_schema,\n",
        "    )\n",
        "    | prompt\n",
        "    | model\n",
        "    | StrOutputParser()\n",
        "    | (lambda x: x.split(\"\\n\\n\")[0])\n",
        ")\n",
        "\n",
        "\n",
        "# Chain to answer\n",
        "template = \"\"\"Based on the table schema below, question, sql query, and sql response, write a natural language response:\n",
        "{schema}\n",
        "\n",
        "Question: {question}\n",
        "SQL Query: {query}\n",
        "SQL Response: {response}\"\"\"  # noqa: E501\n",
        "prompt_response = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"Given an input question and SQL response, convert it to a natural \"\n",
        "            \"language answer. No pre-amble.\",\n",
        "        ),\n",
        "        (\"human\", template),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "# Supply the input types to the prompt\n",
        "class InputType(BaseModel):\n",
        "    question: str\n",
        "\n",
        "\n",
        "sql_answer_chain = (\n",
        "    RunnablePassthrough.assign(query=sql_chain)\n",
        "    | RunnablePassthrough.assign(\n",
        "        schema=get_schema,\n",
        "        response=lambda x: db.run(x[\"query\"],fetch=\"all\"),\n",
        "    )\n",
        "    | RunnablePassthrough.assign(\n",
        "        answer=prompt_response | model | StrOutputParser()\n",
        "    )\n",
        "    | (lambda x: f\"Question: {x['question']}\\n\\nAnswer: {x['answer']}\")\n",
        ")"
      ],
      "metadata": {
        "id": "jsIekt3AbP_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sql_answer_chain.invoke({\"question\":\"List the table of Artists?\"})"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UJhQkBRvhwye",
        "outputId": "deafe21d-2df5-4a5e-a709-89917f3946e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Question: List the table of Artists?\\n\\nAnswer: ArtistId, Name\\n1, AC/DC\\n2, Accept\\n3, Aerosmith\\n...\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sql_chain.invoke({\"question\":\"List the table of Artists?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "koaFOj66gZ1G",
        "outputId": "e5fb9f62-d055-4842-ed36-93f37799b0d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'SELECT ArtistId, Name  FROM Artist\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from typing import Any\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from langchain.utilities import DuckDuckGoSearchAPIWrapper\n",
        "from langchain_community.chat_models import ChatOpenAI\n",
        "from langchain_core.messages import SystemMessage\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import (\n",
        "    Runnable,\n",
        "    RunnableLambda,\n",
        "    RunnableParallel,\n",
        "    RunnablePassthrough,\n",
        ")\n",
        "\n",
        "SEARCH_PROMPT = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"{agent_prompt}\"),\n",
        "        (\n",
        "            \"user\",\n",
        "            \"Write 3 google search queries to search online that form an \"\n",
        "            \"objective opinion from the following: {question}\\n\"\n",
        "            \"You must respond with a list of strings in the following format: \"\n",
        "            '[\"query 1\", \"query 2\", \"query 3\"].',\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "AUTO_AGENT_INSTRUCTIONS = \"\"\"\n",
        "This task involves researching a given topic, regardless of its complexity or the availability of a definitive answer. The research is conducted by a specific agent, defined by its type and role, with each agent requiring distinct instructions.\n",
        "Agent\n",
        "The agent is determined by the field of the topic and the specific name of the agent that could be utilized to research the topic provided. Agents are categorized by their area of expertise, and each agent type is associated with a corresponding emoji.\n",
        "\n",
        "examples:\n",
        "task: \"should I invest in apple stocks?\"\n",
        "response:\n",
        "{\n",
        "    \"agent\": \"ðŸ’° Finance Agent\",\n",
        "    \"agent_role_prompt: \"You are a seasoned finance analyst AI assistant. Your primary goal is to compose comprehensive, astute, impartial, and methodically arranged financial reports based on provided data and trends.\"\n",
        "}\n",
        "task: \"could reselling sneakers become profitable?\"\n",
        "response:\n",
        "{\n",
        "    \"agent\":  \"ðŸ“ˆ Business Analyst Agent\",\n",
        "    \"agent_role_prompt\": \"You are an experienced AI business analyst assistant. Your main objective is to produce comprehensive, insightful, impartial, and systematically structured business reports based on provided business data, market trends, and strategic analysis.\"\n",
        "}\n",
        "task: \"what are the most interesting sites in Tel Aviv?\"\n",
        "response:\n",
        "{\n",
        "    \"agent:  \"ðŸŒ Travel Agent\",\n",
        "    \"agent_role_prompt\": \"You are a world-travelled AI tour guide assistant. Your main purpose is to draft engaging, insightful, unbiased, and well-structured travel reports on given locations, including history, attractions, and cultural insights.\"\n",
        "}\n",
        "\"\"\"  # noqa: E501\n",
        "CHOOSE_AGENT_PROMPT = ChatPromptTemplate.from_messages(\n",
        "    [SystemMessage(content=AUTO_AGENT_INSTRUCTIONS), (\"user\", \"task: {task}\")]\n",
        ")\n",
        "\n",
        "SUMMARY_TEMPLATE = \"\"\"{text}\n",
        "\n",
        "-----------\n",
        "\n",
        "Using the above text, answer in short the following question:\n",
        "\n",
        "> {question}\n",
        "\n",
        "-----------\n",
        "if the question cannot be answered using the text, imply summarize the text. Include all factual information, numbers, stats etc if available.\"\"\"  # noqa: E501\n",
        "SUMMARY_PROMPT = ChatPromptTemplate.from_template(SUMMARY_TEMPLATE)\n",
        "\n",
        "\n",
        "def load_json(s):\n",
        "    try:\n",
        "        return json.loads(s)\n",
        "    except Exception:\n",
        "        return {}\n",
        "\n",
        "\n",
        "search_query = SEARCH_PROMPT | model | StrOutputParser() | load_json\n",
        "choose_agent = (\n",
        "    CHOOSE_AGENT_PROMPT | model | StrOutputParser() | load_json\n",
        ")\n",
        "\n",
        "get_search_queries = (\n",
        "    RunnablePassthrough().assign(\n",
        "        agent_prompt=RunnableParallel({\"task\": lambda x: x})\n",
        "        | choose_agent\n",
        "        | (lambda x: x.get(\"agent_role_prompt\"))\n",
        "    )\n",
        "    | search_query\n",
        ")\n",
        "\n",
        "\n",
        "search_chain = (\n",
        "    get_search_queries\n",
        "    | (lambda x: [{\"question\": q} for q in x])\n",
        "    | sql_answer_chain.map()\n",
        "    | (lambda x: \"\\n\\n\".join(x))\n",
        ")"
      ],
      "metadata": {
        "id": "elMIRJEGtcIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import ConfigurableField\n",
        "\n",
        "WRITER_SYSTEM_PROMPT = \"You are an AI critical thinker research assistant. Your sole purpose is to write well written, critically acclaimed, objective and structured reports on given text.\"  # noqa: E501\n",
        "\n",
        "\n",
        "# Report prompts from https://github.com/assafelovic/gpt-researcher/blob/master/gpt_researcher/master/prompts.py\n",
        "RESEARCH_REPORT_TEMPLATE = \"\"\"Information:\n",
        "--------\n",
        "{research_summary}\n",
        "--------\n",
        "\n",
        "Using the above information, answer the following question or topic: \"{question}\" in a detailed report -- \\\n",
        "The report should focus on the answer to the question, should be well structured, informative, \\\n",
        "in depth, with facts and numbers if available and a minimum of 1,200 words.\n",
        "\n",
        "You should strive to write the report as long as you can using all relevant and necessary information provided.\n",
        "You must write the report with markdown syntax.\n",
        "You MUST determine your own concrete and valid opinion based on the given information. Do NOT deter to general and meaningless conclusions.\n",
        "Write all used source urls at the end of the report, and make sure to not add duplicated sources, but only one reference for each.\n",
        "You must write the report in apa format.\n",
        "Please do your best, this is very important to my career.\"\"\"  # noqa: E501\n",
        "\n",
        "\n",
        "RESOURCE_REPORT_TEMPLATE = \"\"\"Information:\n",
        "--------\n",
        "{research_summary}\n",
        "--------\n",
        "\n",
        "Based on the above information, generate a bibliography recommendation report for the following question or topic: \"{question}\". \\\n",
        "The report should provide a detailed analysis of each recommended resource, explaining how each source can contribute to finding answers to the research question. \\\n",
        "Focus on the relevance, reliability, and significance of each source. \\\n",
        "Ensure that the report is well-structured, informative, in-depth, and follows Markdown syntax. \\\n",
        "Include relevant facts, figures, and numbers whenever available. \\\n",
        "The report should have a minimum length of 1,200 words.\n",
        "\n",
        "Please do your best, this is very important to my career.\"\"\"  # noqa: E501\n",
        "\n",
        "OUTLINE_REPORT_TEMPLATE = \"\"\"Information:\n",
        "--------\n",
        "{research_summary}\n",
        "--------\n",
        "\n",
        "Using the above information, generate an outline for a research report in Markdown syntax for the following question or topic: \"{question}\". \\\n",
        "The outline should provide a well-structured framework for the research report, including the main sections, subsections, and key points to be covered. \\\n",
        "The research report should be detailed, informative, in-depth, and a minimum of 1,200 words. \\\n",
        "Use appropriate Markdown syntax to format the outline and ensure readability.\n",
        "\n",
        "Please do your best, this is very important to my career.\"\"\"  # noqa: E501\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", WRITER_SYSTEM_PROMPT),\n",
        "        (\"user\", RESEARCH_REPORT_TEMPLATE),\n",
        "    ]\n",
        ").configurable_alternatives(\n",
        "    ConfigurableField(\"report_type\"),\n",
        "    default_key=\"research_report\",\n",
        "    resource_report=ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\"system\", WRITER_SYSTEM_PROMPT),\n",
        "            (\"user\", RESOURCE_REPORT_TEMPLATE),\n",
        "        ]\n",
        "    ),\n",
        "    outline_report=ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\"system\", WRITER_SYSTEM_PROMPT),\n",
        "            (\"user\", OUTLINE_REPORT_TEMPLATE),\n",
        "        ]\n",
        "    ),\n",
        ")\n",
        "writer_chain = prompt | model | StrOutputParser()"
      ],
      "metadata": {
        "id": "o4jOl_UztS1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.pydantic_v1 import BaseModel\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "chain_notypes = (\n",
        "    RunnablePassthrough().assign(research_summary=search_chain) | writer_chain\n",
        ")\n",
        "\n",
        "\n",
        "class InputType(BaseModel):\n",
        "    question: str\n",
        "\n",
        "\n",
        "chain = chain_notypes.with_types(input_type=InputType)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(  # noqa: T201\n",
        "        chain.invoke({\"question\": \"recomend me some musics by top artists?\"})\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNQGoXR1tplu",
        "outputId": "0df91ea2-d365-41de-eb7d-aac599d6bb43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Recommendations of Music by Top Artists\n",
            "\n",
            "**Executive Summary:**\n",
            "\n",
            "This report provides recommendations for music by top artists based on the provided information.  The data, while limited to specific songs and albums, allows for a focused recommendation based on perceived popularity and critical acclaim.  The report highlights AC/DC, Accept, and other artists, suggesting albums and songs for listeners seeking similar musical experiences.\n",
            "\n",
            "**Introduction:**\n",
            "\n",
            "The provided information offers a starting point for recommending music by top artists.  While lacking comprehensive sales figures, critical acclaim ratings, and broader artist popularity rankings, the data identifies specific songs and albums that have achieved notable recognition. This report analyzes the provided data to offer targeted suggestions, emphasizing albums and songs considered successful by critics and potentially audiences.\n",
            "\n",
            "\n",
            "**Analysis of Provided Data:**\n",
            "\n",
            "The provided information lists \"For Those About To Rock We Salute You\" by AC/DC, \"Balls to the Wall\" by Accept, and \"Restless and Wild\" by Accept as examples of critically acclaimed albums.  This indicates a focus on hard rock and metal genres.  The list of best-selling songs and top 100 songs further reinforces this genre preference.  However, the lack of specific sales figures and detailed popularity metrics limits the ability to provide definitive recommendations for *all* top artists.\n",
            "\n",
            "\n",
            "**Genre Focus:**\n",
            "\n",
            "Based on the identified albums, the recommendations will primarily center on hard rock and metal.  The report acknowledges that this is a narrow focus, but the data provided is concentrated in this genre.  This report does not include other genres.\n",
            "\n",
            "\n",
            "**Recommendations:**\n",
            "\n",
            "Given the data suggesting a focus on hard rock and metal, the following recommendations are offered:\n",
            "\n",
            "**1. AC/DC:**\n",
            "\n",
            "*   **\"For Those About To Rock We Salute You\":** This album is explicitly mentioned as critically acclaimed.  It's known for its high-energy anthems and iconic guitar riffs.  If you enjoy the energy and intensity of this album, exploring other AC/DC albums like *Back in Black*, *Highway to Hell*, and *Let There Be Rock* would be a logical next step.\n",
            "\n",
            "**2. Accept:**\n",
            "\n",
            "*   **\"Balls to the Wall\":**  Known for its aggressive yet melodic sound, this album is a strong recommendation.  Other Accept albums like *Breaker*, *Restless and Wild*, and *Metal Heart* offer a similar sonic experience.\n",
            "\n",
            "**3.  Further Exploration (Based on Genre and Implied Popularity):**\n",
            "\n",
            "*   **Other Hard Rock and Metal Bands:** Considering the prominence of AC/DC and Accept in the provided list, other hard rock and metal artists of the era (or similar sound) might be good recommendations.\n",
            "\n",
            "**4.  Suggested Songs (From the List):**\n",
            "\n",
            "*   **\"For Those About To Rock We Salute You\":**  A powerful anthem, representative of the album's energy.\n",
            "*   **\"Balls to the Wall\":** Another impactful track known for its aggressive sound.\n",
            "*   **\"Fast As a Shark\":**  The inclusion of this song implies a focus on fast-paced, high-energy tracks.\n",
            "\n",
            "\n",
            "\n",
            "**Limitations of Recommendations:**\n",
            "\n",
            "The recommendations are limited by the following:\n",
            "\n",
            "*   **Lack of Comprehensive Data:** The provided data is insufficient to create a truly comprehensive list of recommendations for *all* top artists.\n",
            "*   **Narrow Genre Focus:**  Recommendations are concentrated in the hard rock and metal genre.\n",
            "*   **No User Preferences:**  The report lacks information about the user's musical preferences, making the recommendations generalized.\n",
            "\n",
            "**Conclusion:**\n",
            "\n",
            "This report offers targeted recommendations based on the provided information.  The suggestions emphasize albums and songs from the hard rock and metal genre that are critically acclaimed and likely popular, based on the limited data.  Further research and user feedback would be necessary to provide a more complete and personalized set of recommendations.\n",
            "\n",
            "**References:**\n",
            "\n",
            "* *No external sources were used. The report's content is based solely on the provided data.*\n",
            "\n",
            "\n",
            "**Disclaimer:**\n",
            "\n",
            "This report is intended to be a starting point for music discovery.  The recommendations are based on limited data and should not be considered exhaustive or definitive.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}