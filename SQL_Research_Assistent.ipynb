{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZJNxY3ME/VJD7MHkYm73c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ranabilal09/SQL-Research-Assistant/blob/main/SQL_Research_Assistent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LA4SFMVnXSa",
        "outputId": "29c4da6d-1950-4bf8-8f3d-fa2587ed3289",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.11)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.10/dist-packages (0.2.59)\n",
            "Requirement already satisfied: langchain-ollama in /usr/local/lib/python3.10/dist-packages (0.2.1)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.10/dist-packages (0.3.11)\n",
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.10/dist-packages (2.0.7)\n",
            "Requirement already satisfied: langserve in /usr/local/lib/python3.10/dist-packages (0.3.0)\n",
            "Requirement already satisfied: arxiv in /usr/local/lib/python3.10/dist-packages (2.1.3)\n",
            "Requirement already satisfied: duckduckgo-search in /usr/local/lib/python3.10/dist-packages (6.4.1)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.9)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.24 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.24)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.2)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.147)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.10.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.4 in /usr/local/lib/python3.10/dist-packages (from langgraph) (2.0.8)\n",
            "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in /usr/local/lib/python3.10/dist-packages (from langgraph) (0.1.43)\n",
            "Requirement already satisfied: ollama<1,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain-ollama) (0.4.4)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.4.0)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.6.1)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (1.2.0)\n",
            "Requirement already satisfied: google-generativeai<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (0.8.3)\n",
            "Requirement already satisfied: httpx<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langserve) (0.27.2)\n",
            "Requirement already satisfied: orjson<4,>=2 in /usr/local/lib/python3.10/dist-packages (from langserve) (3.10.12)\n",
            "Requirement already satisfied: feedparser~=6.0.10 in /usr/local/lib/python3.10/dist-packages (from arxiv) (6.0.11)\n",
            "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.10/dist-packages (from duckduckgo-search) (8.1.7)\n",
            "Requirement already satisfied: primp>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from duckduckgo-search) (0.8.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.23.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.10/dist-packages (from feedparser~=6.0.10->arxiv) (1.0.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.10 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.6.10)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.151.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.25.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.10->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.25.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1.0,>=0.23.0->langserve) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1.0,>=0.23.0->langserve) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1.0,>=0.23.0->langserve) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1.0,>=0.23.0->langserve) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1.0,>=0.23.0->langserve) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1.0,>=0.23.0->langserve) (0.14.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.24->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.24->langchain) (24.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.4->langgraph) (1.1.0)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.66.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.9)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.24->langchain) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1.0,>=0.23.0->langserve) (1.2.2)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.68.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.62.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (3.2.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain langgraph langchain-ollama langchain_community langchain-google-genai langserve arxiv duckduckgo-search"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata , drive\n",
        "import os\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "api = userdata.get('Gemini_Api_Key')\n",
        "os.environ['GOOGLE_API_KEY'] = api\n",
        "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get('langchai_api_key')\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = 'SQL-Research-Assistent'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-C6NdI_n4Lf",
        "outputId": "960b2801-f78d-4cf1-8c2f-9e41ae93cb99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_ollama.llms import OllamaLLM\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.pydantic_v1 import BaseModel\n",
        "from langchain.schema.runnable import RunnablePassthrough,RunnableLambda\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "from langchain.utilities import SQLDatabase\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "import sqlite3\n",
        "\n",
        "import requests\n",
        "from langchain_community.utilities.sql_database import SQLDatabase\n",
        "from sqlalchemy import create_engine\n",
        "from sqlalchemy.pool import StaticPool\n",
        "\n",
        "\n",
        "def get_engine_for_chinook_db():\n",
        "    \"\"\"Pull sql file, populate in-memory database, and create engine.\"\"\"\n",
        "    url = \"https://raw.githubusercontent.com/lerocha/chinook-database/master/ChinookDatabase/DataSources/Chinook_Sqlite.sql\"\n",
        "    response = requests.get(url)\n",
        "    sql_script = response.text\n",
        "\n",
        "    connection = sqlite3.connect(\":memory:\", check_same_thread=False)\n",
        "    connection.executescript(sql_script)\n",
        "    return create_engine(\n",
        "        \"sqlite://\",\n",
        "        creator=lambda: connection,\n",
        "        poolclass=StaticPool,\n",
        "        connect_args={\"check_same_thread\": False},\n",
        "    )\n",
        "\n",
        "\n",
        "engine = get_engine_for_chinook_db()\n",
        "\n",
        "db = SQLDatabase(engine)\n",
        "\n",
        "\n",
        "def get_schema(_):\n",
        "  return db.get_table_info()\n",
        "\n",
        "def get_data(query:str):\n",
        "  return db.run(query)\n",
        "\n",
        "#prompt\n",
        "\n",
        "template = \"\"\"Based on the table schema below , write a SQL query that would anser the user's question:\n",
        "{schema}\n",
        "\n",
        "Question:{question}\n",
        "\n",
        "SQL Query must be in string format and remember that don't use the name 'sql'\n",
        "and backticks (like ```) in response essentially . Use only SELECT and FROM in query, essentially Don't use WHERE word.\n",
        "you must respond string of query in the following format:\n",
        "SELECT column1, column2,...  FROM table_name\n",
        "SQL Query:\"\"\" #node: E501\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"Given a input Question , convert it into a SQL query and remember that don't use the name 'sql' and backtikes (```) in the response. No pre-amble.\"),\n",
        "        (\"human\",template),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model = ChatGoogleGenerativeAI(model= \"gemini-1.5-flash-8b\")\n",
        "\n",
        "#Chain query\n",
        "\n",
        "sql_chain = (\n",
        "    RunnablePassthrough.assign(\n",
        "        schema=get_schema,\n",
        "    )\n",
        "    | prompt\n",
        "    | model\n",
        "    | StrOutputParser()\n",
        "    | (lambda x: x.split(\"\\n\\n\")[0])\n",
        ")\n",
        "\n",
        "\n",
        "# Chain to answer\n",
        "template = \"\"\"Based on the table schema below, question, sql query, and sql response, write a natural language response:\n",
        "{schema}\n",
        "\n",
        "Question: {question}\n",
        "SQL Query: {query}\n",
        "SQL Response: {response}\"\"\"  # noqa: E501\n",
        "prompt_response = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"Given an input question and SQL response, convert it to a natural \"\n",
        "            \"language answer. No pre-amble.\",\n",
        "        ),\n",
        "        (\"human\", template),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "# Supply the input types to the prompt\n",
        "class InputType(BaseModel):\n",
        "    question: str\n",
        "\n",
        "\n",
        "sql_answer_chain = (\n",
        "    RunnablePassthrough.assign(query=sql_chain)\n",
        "    | RunnablePassthrough.assign(\n",
        "        schema=get_schema,\n",
        "        response=lambda x: db.run(x[\"query\"],fetch=\"all\"),\n",
        "    )\n",
        "    | RunnablePassthrough.assign(\n",
        "        answer=prompt_response | model | StrOutputParser()\n",
        "    )\n",
        "    | (lambda x: f\"Question: {x['question']}\\n\\nAnswer: {x['answer']}\")\n",
        ")"
      ],
      "metadata": {
        "id": "jsIekt3AbP_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sql_answer_chain.invoke({\"question\":\"List the table of Artists?\"})"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UJhQkBRvhwye",
        "outputId": "deafe21d-2df5-4a5e-a709-89917f3946e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Question: List the table of Artists?\\n\\nAnswer: ArtistId, Name\\n1, AC/DC\\n2, Accept\\n3, Aerosmith\\n...\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sql_chain.invoke({\"question\":\"List the table of Artists?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "koaFOj66gZ1G",
        "outputId": "e5fb9f62-d055-4842-ed36-93f37799b0d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'SELECT ArtistId, Name  FROM Artist\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from typing import Any\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from langchain.utilities import DuckDuckGoSearchAPIWrapper\n",
        "from langchain_community.chat_models import ChatOpenAI\n",
        "from langchain_core.messages import SystemMessage\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import (\n",
        "    Runnable,\n",
        "    RunnableLambda,\n",
        "    RunnableParallel,\n",
        "    RunnablePassthrough,\n",
        ")\n",
        "\n",
        "SEARCH_PROMPT = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"{agent_prompt}\"),\n",
        "        (\n",
        "            \"user\",\n",
        "            \"Write 3 google search queries to search online that form an \"\n",
        "            \"objective opinion from the following: {question}\\n\"\n",
        "            \"You must respond with a list of strings in the following format: \"\n",
        "            '[\"query 1\", \"query 2\", \"query 3\"].',\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "AUTO_AGENT_INSTRUCTIONS = \"\"\"\n",
        "This task involves researching a given topic, regardless of its complexity or the availability of a definitive answer. The research is conducted by a specific agent, defined by its type and role, with each agent requiring distinct instructions.\n",
        "Agent\n",
        "The agent is determined by the field of the topic and the specific name of the agent that could be utilized to research the topic provided. Agents are categorized by their area of expertise, and each agent type is associated with a corresponding emoji.\n",
        "\n",
        "examples:\n",
        "task: \"should I invest in apple stocks?\"\n",
        "response:\n",
        "{\n",
        "    \"agent\": \"üí∞ Finance Agent\",\n",
        "    \"agent_role_prompt: \"You are a seasoned finance analyst AI assistant. Your primary goal is to compose comprehensive, astute, impartial, and methodically arranged financial reports based on provided data and trends.\"\n",
        "}\n",
        "task: \"could reselling sneakers become profitable?\"\n",
        "response:\n",
        "{\n",
        "    \"agent\":  \"üìà Business Analyst Agent\",\n",
        "    \"agent_role_prompt\": \"You are an experienced AI business analyst assistant. Your main objective is to produce comprehensive, insightful, impartial, and systematically structured business reports based on provided business data, market trends, and strategic analysis.\"\n",
        "}\n",
        "task: \"what are the most interesting sites in Tel Aviv?\"\n",
        "response:\n",
        "{\n",
        "    \"agent:  \"üåç Travel Agent\",\n",
        "    \"agent_role_prompt\": \"You are a world-travelled AI tour guide assistant. Your main purpose is to draft engaging, insightful, unbiased, and well-structured travel reports on given locations, including history, attractions, and cultural insights.\"\n",
        "}\n",
        "\"\"\"  # noqa: E501\n",
        "CHOOSE_AGENT_PROMPT = ChatPromptTemplate.from_messages(\n",
        "    [SystemMessage(content=AUTO_AGENT_INSTRUCTIONS), (\"user\", \"task: {task}\")]\n",
        ")\n",
        "\n",
        "SUMMARY_TEMPLATE = \"\"\"{text}\n",
        "\n",
        "-----------\n",
        "\n",
        "Using the above text, answer in short the following question:\n",
        "\n",
        "> {question}\n",
        "\n",
        "-----------\n",
        "if the question cannot be answered using the text, imply summarize the text. Include all factual information, numbers, stats etc if available.\"\"\"  # noqa: E501\n",
        "SUMMARY_PROMPT = ChatPromptTemplate.from_template(SUMMARY_TEMPLATE)\n",
        "\n",
        "\n",
        "def load_json(s):\n",
        "    try:\n",
        "        return json.loads(s)\n",
        "    except Exception:\n",
        "        return {}\n",
        "\n",
        "\n",
        "search_query = SEARCH_PROMPT | model | StrOutputParser() | load_json\n",
        "choose_agent = (\n",
        "    CHOOSE_AGENT_PROMPT | model | StrOutputParser() | load_json\n",
        ")\n",
        "\n",
        "get_search_queries = (\n",
        "    RunnablePassthrough().assign(\n",
        "        agent_prompt=RunnableParallel({\"task\": lambda x: x})\n",
        "        | choose_agent\n",
        "        | (lambda x: x.get(\"agent_role_prompt\"))\n",
        "    )\n",
        "    | search_query\n",
        ")\n",
        "\n",
        "\n",
        "search_chain = (\n",
        "    get_search_queries\n",
        "    | (lambda x: [{\"question\": q} for q in x])\n",
        "    | sql_answer_chain.map()\n",
        "    | (lambda x: \"\\n\\n\".join(x))\n",
        ")"
      ],
      "metadata": {
        "id": "elMIRJEGtcIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import ConfigurableField\n",
        "\n",
        "WRITER_SYSTEM_PROMPT = \"You are an AI critical thinker research assistant. Your sole purpose is to write well written, critically acclaimed, objective and structured reports on given text.\"  # noqa: E501\n",
        "\n",
        "\n",
        "# Report prompts from https://github.com/assafelovic/gpt-researcher/blob/master/gpt_researcher/master/prompts.py\n",
        "RESEARCH_REPORT_TEMPLATE = \"\"\"Information:\n",
        "--------\n",
        "{research_summary}\n",
        "--------\n",
        "\n",
        "Using the above information, answer the following question or topic: \"{question}\" in a detailed report -- \\\n",
        "The report should focus on the answer to the question, should be well structured, informative, \\\n",
        "in depth, with facts and numbers if available and a minimum of 1,200 words.\n",
        "\n",
        "You should strive to write the report as long as you can using all relevant and necessary information provided.\n",
        "You must write the report with markdown syntax.\n",
        "You MUST determine your own concrete and valid opinion based on the given information. Do NOT deter to general and meaningless conclusions.\n",
        "Write all used source urls at the end of the report, and make sure to not add duplicated sources, but only one reference for each.\n",
        "You must write the report in apa format.\n",
        "Please do your best, this is very important to my career.\"\"\"  # noqa: E501\n",
        "\n",
        "\n",
        "RESOURCE_REPORT_TEMPLATE = \"\"\"Information:\n",
        "--------\n",
        "{research_summary}\n",
        "--------\n",
        "\n",
        "Based on the above information, generate a bibliography recommendation report for the following question or topic: \"{question}\". \\\n",
        "The report should provide a detailed analysis of each recommended resource, explaining how each source can contribute to finding answers to the research question. \\\n",
        "Focus on the relevance, reliability, and significance of each source. \\\n",
        "Ensure that the report is well-structured, informative, in-depth, and follows Markdown syntax. \\\n",
        "Include relevant facts, figures, and numbers whenever available. \\\n",
        "The report should have a minimum length of 1,200 words.\n",
        "\n",
        "Please do your best, this is very important to my career.\"\"\"  # noqa: E501\n",
        "\n",
        "OUTLINE_REPORT_TEMPLATE = \"\"\"Information:\n",
        "--------\n",
        "{research_summary}\n",
        "--------\n",
        "\n",
        "Using the above information, generate an outline for a research report in Markdown syntax for the following question or topic: \"{question}\". \\\n",
        "The outline should provide a well-structured framework for the research report, including the main sections, subsections, and key points to be covered. \\\n",
        "The research report should be detailed, informative, in-depth, and a minimum of 1,200 words. \\\n",
        "Use appropriate Markdown syntax to format the outline and ensure readability.\n",
        "\n",
        "Please do your best, this is very important to my career.\"\"\"  # noqa: E501\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", WRITER_SYSTEM_PROMPT),\n",
        "        (\"user\", RESEARCH_REPORT_TEMPLATE),\n",
        "    ]\n",
        ").configurable_alternatives(\n",
        "    ConfigurableField(\"report_type\"),\n",
        "    default_key=\"research_report\",\n",
        "    resource_report=ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\"system\", WRITER_SYSTEM_PROMPT),\n",
        "            (\"user\", RESOURCE_REPORT_TEMPLATE),\n",
        "        ]\n",
        "    ),\n",
        "    outline_report=ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\"system\", WRITER_SYSTEM_PROMPT),\n",
        "            (\"user\", OUTLINE_REPORT_TEMPLATE),\n",
        "        ]\n",
        "    ),\n",
        ")\n",
        "writer_chain = prompt | model | StrOutputParser()"
      ],
      "metadata": {
        "id": "o4jOl_UztS1h"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.pydantic_v1 import BaseModel\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "chain = (\n",
        "    RunnablePassthrough().assign(research_summary=search_chain) | writer_chain\n",
        ")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(  # noqa: T201\n",
        "        chain.invoke({\"question\": \"recomend me some musics by top artists?\"})\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNQGoXR1tplu",
        "outputId": "3c9328d9-db4c-4775-dde6-d67a44cc23dd"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Recommendations for Music by Top Artists\n",
            "\n",
            "**Executive Summary:**\n",
            "\n",
            "This report provides recommendations for music by top artists based on available data, focusing on best-selling songs, popular albums from 2023, and critically acclaimed works.  The limited data restricts a comprehensive analysis, but allows for targeted suggestions based on specific metrics.  The report highlights the diverse musical styles represented by the mentioned artists, including rock, pop, and acoustic genres.\n",
            "\n",
            "**Introduction:**\n",
            "\n",
            "The request \"recommend me some music by top artists\" is broad.  To provide meaningful recommendations, this report leverages the limited data provided regarding best-selling songs, popular albums released in 2023, and critically acclaimed works.  The analysis is necessarily constrained by the absence of broader artist rankings, critical reviews, and listener demographics. This report focuses on the provided data to offer specific musical suggestions.\n",
            "\n",
            "**Analysis of Best-Selling Songs:**\n",
            "\n",
            "The data identifies \"A Cor Do Sol\" by \"Ac√∫stico MTV [Live]\" and \"A Melhor Forma\" by \"Ac√∫stico\" as top-selling songs.  This suggests a strong performance in sales or streaming metrics within a given market (likely Brazil, given the song titles).  Unfortunately, the report lacks details about the artists' broader success, global reach, or specific timeframes for these sales figures.  This information would be crucial for a more nuanced recommendation.  However, these songs represent a potential entry point for exploring the acoustic and live performance aspects of the artists' work.\n",
            "\n",
            "**Analysis of Popular Music Albums (2023):**\n",
            "\n",
            "The report lists several popular albums from 2023 by well-known artists, including AC/DC, Accept, Aerosmith, and Alanis Morissette. This suggests a continued commercial viability for these artists, particularly in the rock genre.  The specific albums listed‚Äî *For Those About To Rock We Salute You*, *Balls to the Wall*, *Restless and Wild*, *Let There Be Rock*, *Big Ones*, and *Jagged Little Pill*‚Äîrepresent a diverse range of musical styles within the rock and alternative genres.  It is worth noting that the absence of album sales figures or streaming numbers limits the ability to discern the true popularity and commercial success of these releases.\n",
            "\n",
            "**Analysis of Critically Acclaimed Songs:**\n",
            "\n",
            "The data indicates albums by AC/DC, Accept, and other artists as critically acclaimed.  This implies a favorable reception from music critics, but the lack of specific songs or album reviews makes it difficult to draw further conclusions.  It's possible some of the popular albums listed are also critically acclaimed, though no specific songs are highlighted.   To provide more substantial recommendations, a deeper understanding of the critical reception would be required.\n",
            "\n",
            "**Recommendations:**\n",
            "\n",
            "Given the limited data, the following recommendations are offered based on the available information:\n",
            "\n",
            "* **For fans of acoustic music:**  Explore \"A Cor Do Sol\" by \"Ac√∫stico MTV [Live]\" and \"A Melhor Forma\" by \"Ac√∫stico.\"  These songs represent a starting point for discovering the acoustic styles of these artists.\n",
            "\n",
            "* **For rock music enthusiasts:**  Explore the albums listed from AC/DC, Accept, and Aerosmith.  These represent well-established rock acts, and albums like *For Those About To Rock We Salute You*, *Balls to the Wall*, *Restless and Wild*, *Let There Be Rock*, *Big Ones*, and *Jagged Little Pill* are likely to offer diverse listening experiences.\n",
            "\n",
            "* **For a broader musical exploration:**  Given the lack of specific information, additional research into the artists' complete discographies and critical reception is encouraged.  This will allow for a more informed and nuanced recommendation.\n",
            "\n",
            "**Conclusion:**\n",
            "\n",
            "This report offers limited recommendations due to the restricted nature of the input data.  The information provided focuses on specific sales and popularity metrics, but lacks crucial context regarding critical reception and broader artistic impact.  To provide more comprehensive recommendations, additional data on artist rankings, album sales, critical reviews, and listener demographics would be essential.\n",
            "\n",
            "\n",
            "**References**\n",
            "\n",
            "(No URLs provided, therefore no references can be cited.)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade fastapi uvicorn langserve sse_starlette python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaR8YW3jxR9c",
        "outputId": "4afa7c7f-e068-4c93-ae00-f1907457085c"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (0.115.6)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.10/dist-packages (0.32.1)\n",
            "Requirement already satisfied: langserve in /usr/local/lib/python3.10/dist-packages (0.3.0)\n",
            "Requirement already satisfied: sse_starlette in /usr/local/lib/python3.10/dist-packages (2.1.3)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (0.41.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi) (2.10.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (4.12.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (0.14.0)\n",
            "Requirement already satisfied: httpx<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langserve) (0.27.2)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.3 in /usr/local/lib/python3.10/dist-packages (from langserve) (0.3.24)\n",
            "Requirement already satisfied: orjson<4,>=2 in /usr/local/lib/python3.10/dist-packages (from langserve) (3.10.12)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from sse_starlette) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1.0,>=0.23.0->langserve) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1.0,>=0.23.0->langserve) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1.0,>=0.23.0->langserve) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1.0,>=0.23.0->langserve) (1.3.1)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3->langserve) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3->langserve) (1.33)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3->langserve) (0.1.147)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3->langserve) (24.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3->langserve) (9.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.27.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->sse_starlette) (1.2.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3->langserve) (3.0.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3->langserve) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3->langserve) (1.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3->langserve) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3->langserve) (2.2.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi import FastAPI\n",
        "import uvicorn\n",
        "from langserve import add_routes\n",
        "\n",
        "import nest_asyncio\n",
        "\n",
        "# This is the crucial fix for Jupyter/Colab environments\n",
        "nest_asyncio.apply()\n",
        "\n",
        "\n",
        "app = FastAPI(\n",
        "  title=\"LangChain Server\",\n",
        "  version=\"1.0\",\n",
        "  description=\"A simple api server using Langchain's Runnable interfaces\",\n",
        ")\n",
        "\n",
        "add_routes(app, chain, path=\"/sql-research\")\n",
        "\n",
        "if  __name__ == \"__main__\":\n",
        "  uvicorn.run(app,host=\"localhost\", port=8000)"
      ],
      "metadata": {
        "id": "TtF1Z6XfxP-3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}